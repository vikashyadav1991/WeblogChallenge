{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import re\n",
    "# Load PySpark\n",
    "spark = SparkSession.builder.appName('Analysis').getOrCreate()\n",
    "sc = pyspark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing & Analytical goals:\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the raw log file into a RDD\n",
    "regx = r\"^(\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (\\S+) \\S+ (.*) (\\S+) (\\S+)$\"\n",
    "rdd = sc.textFile(\"data/2015_07_22_mktplace_shop_web_log_sample.log.gz\").map(lambda x: re.split(regx, x)[1:17])\n",
    "rdd_ = rdd.map(lambda x: (x[0], x[1], x[2], x[3], float(x[4]), float(x[5]), float(x[6]), int(x[7]), int(x[8]), int(x[9]), int(x[10]), x[11].strip('\"'), x[12].lower(), x[13].strip('\"'), x[14], x[15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for parsed log\n",
    "Schema = T.StructType([T.StructField(\"timestamp\", T.StringType(), True),\n",
    "                                    T.StructField(\"elb\", T.StringType(), True),\n",
    "                                    T.StructField(\"client_port\", T.StringType(), True),\n",
    "                                    T.StructField(\"backend_port\", T.StringType(), True),\n",
    "                                    T.StructField(\"request_processing_time\", T.DoubleType(), True),\n",
    "                                    T.StructField(\"backend_processing_time\", T.DoubleType(), True),\n",
    "                                    T.StructField(\"response_processing_time\", T.DoubleType(), True),\n",
    "                                    T.StructField(\"elb_status_code\", T.LongType(), True),\n",
    "                                    T.StructField(\"backend_status_code\", T.LongType(), True),\n",
    "                                    T.StructField(\"received_bytes\", T.LongType(), True),\n",
    "                                    T.StructField(\"sent_bytes\", T.LongType(), True),\n",
    "                                    T.StructField(\"request_type\", T.StringType(), True), #GET, POST etc.\n",
    "                                    T.StructField(\"request\", T.StringType(), True),\n",
    "                                    T.StructField(\"user_agent\", T.StringType(), True),\n",
    "                                    T.StructField(\"ssl_cipher\", T.StringType(), True),\n",
    "                                    T.StructField(\"ssl_protocol\", T.StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.csv(\"data/2015_07_22_mktplace_shop_web_log_sample.log.gz\", Schema, sep = \" \", ignoreLeadingWhiteSpace=True, ignoreTrailingWhiteSpace=True).cache()\n",
    "\n",
    "# RDD converted to DataFame\n",
    "df = spark.createDataFrame(rdd_, schema=Schema).withColumn(\"client_ip\", F.split(F.col(\"client_port\"), ':')[0])\\\n",
    ".withColumn(\"unix_timestamp\", F.unix_timestamp(F.col(\"timestamp\").substr(0,19).cast('timestamp')))\\\n",
    ".repartition(rdd_.getNumPartitions(), \"client_ip\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------+----------------+------------------+------------+-----------------------+-----------------------+------------------------+------------------+-------------------+------------------+-----------------+------------+-----------------------------------------+---------------------------------------------------------------------------------------------------+-----------------------+------------+------------+--------------------+\n",
      "|summary|timestamp                  |elb             |client_port       |backend_port|request_processing_time|backend_processing_time|response_processing_time|elb_status_code   |backend_status_code|received_bytes    |sent_bytes       |request_type|request                                  |user_agent                                                                                         |ssl_cipher             |ssl_protocol|client_ip   |unix_timestamp      |\n",
      "+-------+---------------------------+----------------+------------------+------------+-----------------------+-----------------------+------------------------+------------------+-------------------+------------------+-----------------+------------+-----------------------------------------+---------------------------------------------------------------------------------------------------+-----------------------+------------+------------+--------------------+\n",
      "|count  |1158500                    |1158500         |1158500           |1158500     |1158500                |1158500                |1158500                 |1158500           |1158500            |1158500           |1158500          |1158500     |1158500                                  |1158500                                                                                            |1158500                |1158500     |1158500     |1158500             |\n",
      "|mean   |null                       |null            |null              |null        |-1.1705134829516323E-4 |0.033057569863616035   |-1.1899541907570301E-4  |216.7690315062581 |216.69855416486837 |27.532892533448425|5488.19137850669 |null        |null                                     |null                                                                                               |null                   |null        |null        |1.4375833608891368E9|\n",
      "|stddev |null                       |null            |null              |null        |0.011824675161465422   |0.36602516685579267    |0.011824654382180055    |42.312951921691166|42.25417090646637  |204.4928732755386 |15629.35180609112|null        |null                                     |null                                                                                               |null                   |null        |null        |15682.792221806674  |\n",
      "|min    |2015-07-22T02:40:06.499174Z|marketpalce-shop|1.186.101.79:50613|-           |-1.0                   |-1.0                   |-1.0                    |200               |0                  |0                 |0                |DELETE      |http://123.249.24.233:80/post_ip_port.php|                                                                                                   |-                      |-           |1.186.101.79|1437547206          |\n",
      "|max    |2015-07-22T21:10:27.993803Z|marketpalce-shop|99.8.170.3:60015  |10.0.6.99:81|1.51E-4                |58.698117              |0.001433                |504               |504                |23403             |1068957          |PUT         |https://www.paytm.com:443/tickets        |ultrafone 105+(Linux; U;) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0.3 Mobile Safari/534.30|ECDHE-RSA-AES128-SHA256|TLSv1.2     |99.8.170.3  |1437613827          |\n",
      "+-------+---------------------------+----------------+------------------+------------+-----------------------+-----------------------+------------------------+------------------+-------------------+------------------+-----------------+------------+-----------------------------------------+---------------------------------------------------------------------------------------------------+-----------------------+------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the summary for the dataframe\n",
    "df.describe().show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Sessionize the web log by IP. Sessionize = aggregrate all page hits by visitor/IP during a session.\n",
    "---------\n",
    "https://en.wikipedia.org/wiki/Session_(web_analytics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF to assign session_id to each request.\n",
    "# IP represents individual User\n",
    "# Each user session can be of maximum 15 minutes\n",
    "\n",
    "session_schema = T.ArrayType(T.StructType([T.StructField(\"client_port\", T.StringType(), False),\n",
    "                                           T.StructField(\"timestamp\", T.StringType(), False),\n",
    "                                           T.StructField(\"session_id\", T.IntegerType(), False)]))\n",
    "\n",
    "# UDF to assign session_id to each record\n",
    "def sessionize(row):\n",
    "    unix_timestamp = list(list(zip(*row))[0])\n",
    "    timestamp = list(list(zip(*row))[1])\n",
    "    client_port = list(list(zip(*row))[2])\n",
    "    timeframe = 15*60 # Time Frame 900 Seconds\n",
    "    first_element = unix_timestamp[0]\n",
    "    current_sess_id = 1\n",
    "    session_id = [current_sess_id]\n",
    "    for i in unix_timestamp[1:]:\n",
    "        if (i - first_element) < timeframe:\n",
    "            session_id.append(current_sess_id)\n",
    "        else:\n",
    "            first_element = i\n",
    "            current_sess_id += 1\n",
    "            session_id.append(current_sess_id)\n",
    "    return zip(client_port, timestamp, session_id)\n",
    "\n",
    "udf_s = F.udf(lambda x, y, z: sessionize(sorted(zip(z,y,x))), session_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.groupby('client_ip').agg(udf_s(F.collect_list(\"client_port\"), F.collect_list(\"timestamp\"), F.collect_list(\"unix_timestamp\")).alias('session'))\\\n",
    ".select(\"client_ip\", F.explode(\"session\").alias(\"session\"))\\\n",
    ".select(\"client_ip\", F.col(\"session\").client_port.alias(\"client_port\"), F.col(\"session\").timestamp.alias(\"timestamp\"), F.col(\"session\").session_id.alias(\"session_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+---------------------------+----------+\n",
      "|client_ip   |client_port       |timestamp                  |session_id|\n",
      "+------------+------------------+---------------------------+----------+\n",
      "|1.186.101.79|1.186.101.79:50614|2015-07-22T10:45:55.881199Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:45:55.885488Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:46:27.839734Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:46:56.591943Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:47:01.782695Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:47:06.893987Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:47:07.616869Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:47:07.844446Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:47:18.072370Z|1         |\n",
      "|1.186.101.79|1.186.101.79:50613|2015-07-22T10:47:28.084661Z|1         |\n",
      "+------------+------------------+---------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_.select(\"client_ip\", \"client_port\", \"timestamp\", \"session_id\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join\n",
    "df_1 = df.join(df_, ['client_port', 'timestamp'], 'inner').drop(df_.timestamp).drop(df_.client_ip).drop(df_.client_port).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Determine the average session time\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine the average session time\n",
    "# def get_avg_session_time(df):\n",
    "#     df_ = df.groupby(\"client_ip\", \"session_id\").agg(((F.unix_timestamp(F.max(\"timestamp\")) - F.unix_timestamp(F.min(\"timestamp\")) + 1)/60).alias(\"session_length\"))\n",
    "#     avg_session_time = df_.agg(F.avg(\"session_length\").alias(\"avg_session_time\")).collect()[0][\"avg_session_time\"]\n",
    "#     return avg_session_time\n",
    "\n",
    "# # Find the most engaged users, ie the IPs with the longest session times\n",
    "# def get_most_engaged_user(df):\n",
    "#     df_ = df.groupby(\"client_ip\", \"session_id\").agg(F.min(\"timestamp\").alias(\"from_timestamp\"), F.max(\"timestamp\").alias(\"to_timestamp\"), ((F.unix_timestamp(F.max(\"timestamp\")) - F.unix_timestamp(F.min(\"timestamp\")) + 1)/60).alias(\"session_length\"))\n",
    "#     return df_.orderBy(\"session_length\", ascending=False)\n",
    "\n",
    "# # Determine unique URL visits per session. To clarify, count a hit to a unique URL only once per session.\n",
    "# def get_unique_url_request(df):\n",
    "#     return df.groupby(\"client_ip\", \"session_id\").agg(F.countDistinct(\"request\").alias(\"unique_url_request\"))\n",
    "\n",
    "def analyze(df):\n",
    "    df_ = df.groupby(\"client_ip\", \"session_id\").agg(F.min(\"timestamp\").alias(\"from_timestamp\"), F.max(\"timestamp\").alias(\"to_timestamp\"), ((F.max(\"unix_timestamp\") - F.min(\"unix_timestamp\") + 1)).alias(\"session_length\"), F.countDistinct(\"request\").alias(\"unique_url_request\"))\n",
    "    return df_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = analyze(df_1.select(\"client_ip\", \"session_id\", \"timestamp\", \"unix_timestamp\", \"request\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------------------------+---------------------------+--------------+------------------+\n",
      "|client_ip    |session_id|from_timestamp             |to_timestamp               |session_length|unique_url_request|\n",
      "+-------------+----------+---------------------------+---------------------------+--------------+------------------+\n",
      "|1.186.37.28  |1         |2015-07-22T10:31:24.915677Z|2015-07-22T10:34:51.085597Z|208           |52                |\n",
      "|1.187.203.5  |1         |2015-07-22T16:41:16.877706Z|2015-07-22T16:42:40.378450Z|85            |4                 |\n",
      "|1.187.205.138|1         |2015-07-22T17:42:16.189614Z|2015-07-22T17:42:29.109317Z|14            |3                 |\n",
      "|1.187.247.221|1         |2015-07-22T10:48:03.596780Z|2015-07-22T10:49:50.318141Z|108           |4                 |\n",
      "|1.187.249.242|1         |2015-07-22T16:22:01.577228Z|2015-07-22T16:22:28.014105Z|28            |10                |\n",
      "|1.22.120.162 |1         |2015-07-22T16:44:24.902959Z|2015-07-22T16:44:38.150257Z|15            |5                 |\n",
      "|1.22.128.213 |1         |2015-07-22T16:43:30.377785Z|2015-07-22T16:43:36.269095Z|7             |4                 |\n",
      "|1.22.174.33  |1         |2015-07-22T16:22:20.552041Z|2015-07-22T16:24:07.673715Z|108           |9                 |\n",
      "|1.22.205.107 |1         |2015-07-22T16:20:42.116835Z|2015-07-22T16:20:42.116835Z|1             |1                 |\n",
      "|1.23.128.2   |1         |2015-07-22T18:04:03.767028Z|2015-07-22T18:05:08.489471Z|66            |6                 |\n",
      "+-------------+----------+---------------------------+---------------------------+--------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Distinct Sessions = 113382\n",
      "Average Session Time (Seconds) = 90.36611631475895\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Distinct Sessions = {}\".format(df_2.count()))\n",
    "print(\"Average Session Time (Seconds) = {}\".format(df_2.agg(F.avg(\"session_length\").alias(\"avg_session_time\")).collect()[0][\"avg_session_time\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Determine unique URL visits per session. To clarify, count a hit to a unique URL only once per session.\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Clients/IP sessions with most number of unique URL requests\n",
      "+-------------+---------------------------+---------------------------+----------+------------------+\n",
      "|client_ip    |from_timestamp             |to_timestamp               |session_id|unique_url_request|\n",
      "+-------------+---------------------------+---------------------------+----------+------------------+\n",
      "|119.81.61.166|2015-07-22T16:10:28.394091Z|2015-07-22T16:25:05.211263Z|8         |8016              |\n",
      "|52.74.219.71 |2015-07-22T16:10:28.056562Z|2015-07-22T16:25:05.202249Z|8         |5478              |\n",
      "|52.74.219.71 |2015-07-22T10:30:28.220275Z|2015-07-22T10:39:47.427020Z|5         |5057              |\n",
      "|106.186.23.95|2015-07-22T21:05:28.048908Z|2015-07-22T21:10:27.952944Z|12        |4656              |\n",
      "|119.81.61.166|2015-07-22T17:40:28.042128Z|2015-07-22T17:45:28.037648Z|10        |3928              |\n",
      "|119.81.61.166|2015-07-22T18:00:28.603200Z|2015-07-22T18:05:27.768298Z|11        |3637              |\n",
      "|119.81.61.166|2015-07-22T02:40:06.770390Z|2015-07-22T02:45:03.781765Z|1         |3334              |\n",
      "|52.74.219.71 |2015-07-22T18:00:28.444086Z|2015-07-22T18:05:27.566212Z|11        |2907              |\n",
      "|119.81.61.166|2015-07-22T21:05:28.042763Z|2015-07-22T21:10:27.654732Z|12        |2841              |\n",
      "|119.81.61.166|2015-07-22T16:40:28.222688Z|2015-07-22T16:44:48.462751Z|9         |2786              |\n",
      "|106.51.132.54|2015-07-22T16:10:28.051642Z|2015-07-22T16:14:52.013537Z|1         |2609              |\n",
      "|52.74.219.71 |2015-07-22T09:00:28.348141Z|2015-07-22T09:04:43.352165Z|4         |2572              |\n",
      "|52.74.219.71 |2015-07-22T10:45:28.320258Z|2015-07-22T10:49:52.557803Z|6         |2569              |\n",
      "|52.74.219.71 |2015-07-22T17:40:28.080159Z|2015-07-22T17:45:27.904253Z|10        |2535              |\n",
      "|52.74.219.71 |2015-07-22T21:05:28.077091Z|2015-07-22T21:10:27.950160Z|12        |2466              |\n",
      "|52.74.219.71 |2015-07-22T16:40:28.370059Z|2015-07-22T16:44:48.434167Z|9         |2458              |\n",
      "|52.74.219.71 |2015-07-22T05:10:07.342661Z|2015-07-22T05:15:07.066653Z|2         |2037              |\n",
      "|52.74.219.71 |2015-07-22T11:00:28.722157Z|2015-07-22T11:04:57.382184Z|7         |1958              |\n",
      "|54.169.20.106|2015-07-22T16:10:29.567476Z|2015-07-22T16:24:03.207080Z|3         |1896              |\n",
      "|119.81.61.166|2015-07-22T06:55:07.896678Z|2015-07-22T07:00:07.059378Z|3         |1671              |\n",
      "+-------------+---------------------------+---------------------------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_2.unique_url_request contains the number of unique URL request made by a client during a session.\n",
    "print(\"20 Clients/IP sessions with most number of unique URL requests\")\n",
    "df_2.select(\"client_ip\", \"from_timestamp\", \"to_timestamp\", \"session_id\", \"unique_url_request\").sort(\"unique_url_request\", ascending=False).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Find the most engaged users, ie the IPs with the longest session times.\n",
    "------------\n",
    "\n",
    "Changes required to extract average session time per user.\n",
    "Each IP represents a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Most Engaged Users (IP with largest total session times)\n",
      "+---------------+------------------------------+\n",
      "|client_ip      |total_session_length (Minutes)|\n",
      "+---------------+------------------------------+\n",
      "|54.251.151.39  |87.38333333333334             |\n",
      "|121.58.175.128 |82.63333333333334             |\n",
      "|220.226.206.7  |81.66666666666667             |\n",
      "|180.179.213.94 |73.3                          |\n",
      "|52.74.219.71   |71.55                         |\n",
      "|119.81.61.166  |71.45                         |\n",
      "|54.252.254.204 |71.38333333333334             |\n",
      "|122.252.231.14 |69.65                         |\n",
      "|180.179.213.71 |69.23333333333333             |\n",
      "|207.46.13.22   |67.7                          |\n",
      "|106.186.23.95  |66.1                          |\n",
      "|176.34.159.236 |65.66666666666667             |\n",
      "|54.255.254.236 |64.96666666666667             |\n",
      "|168.235.197.212|63.86666666666667             |\n",
      "|54.232.40.76   |63.56666666666667             |\n",
      "|54.243.31.236  |63.1                          |\n",
      "|116.50.59.180  |62.21666666666667             |\n",
      "|177.71.207.172 |61.93333333333333             |\n",
      "|54.183.255.140 |61.916666666666664            |\n",
      "|125.19.44.66   |61.43333333333333             |\n",
      "+---------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"20 Most Engaged Users (IP with largest total session times)\")\n",
    "df_2.groupby(\"client_ip\").agg((F.sum(\"session_length\")/F.lit(60.0)).alias(\"total_session_length (Minutes)\")).sort(\"total_session_length (Minutes)\", ascending=False).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional questions for Machine Learning Engineer (MLE) candidates:\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_1 = df_1.withColumn(\"hour\", df.timestamp.substr(12,2).cast('integer'))\\\n",
    ".withColumn(\"minute\", df.timestamp.substr(15,2).cast('integer'))\\\n",
    ".withColumn(\"timestamp\", F.col(\"timestamp\").substr(0,16).cast('timestamp')).withColumn(\"client_ip\", F.split(F.col(\"client_port\"), ':')[0])\\\n",
    "\n",
    "\n",
    "df_t_2 = df_t_1.groupby(\"timestamp\").agg((F.count(\"timestamp\")/60).alias(\"load\"), \n",
    "                                F.avg(\"received_bytes\").alias(\"received_bytes\"), \n",
    "                                F.avg(\"sent_bytes\").alias(\"sent_bytes\"), \n",
    "                                F.countDistinct(\"request\").alias(\"unique_request_count\"), \n",
    "                                F.countDistinct(\"client_ip\").alias(\"unique_ip_count\"), \n",
    "                                F.first(\"hour\").alias(\"hour\"), \n",
    "                                F.first(\"minute\").alias(\"minute\")).sort([\"hour\", \"minute\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy().orderBy([\"hour\", \"minute\"])\n",
    "df_t_3 = df_t_2.select(\"hour\", \"minute\", F.lag(\"sent_bytes\").over(w).alias(\"prev_sent_bytes\"), F.lag(\"received_bytes\").over(w).alias(\"prev_received_bytes\"), F.lag(\"unique_request_count\").over(w).alias(\"prev_unique_request_count\"), F.lag(\"unique_ip_count\").over(w).alias(\"prev_unique_ip_count\"), \"load\").where(F.col(\"prev_sent_bytes\").isNotNull()).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_t_3.randomSplit([0.8, 0.2], seed=2019)\n",
    "training = train.withColumn(\"label\", F.col(\"load\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Predict the expected load (requests/second) in the next minute\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"hour\", \"minute\", \"prev_sent_bytes\", \"prev_received_bytes\", \n",
    "                                       \"prev_unique_request_count\", \"prev_unique_ip_count\"], outputCol=\"vectorized\")\n",
    "\n",
    "# df_t_4 = assembler.transform(df_t_3)\n",
    "polyExpansion = PolynomialExpansion(inputCol=\"vectorized\", outputCol=\"features\")\n",
    "lr = LinearRegression(maxIter=100, featuresCol=\"features\", labelCol=\"label\")\n",
    "pipeline = Pipeline(stages=[assembler, polyExpansion, lr])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(polyExpansion.degree, [1, 2, 3])\\\n",
    ".addGrid(lr.regParam, [0.1, 0.01, 0.001]).build()\n",
    "# .addGrid(lr.fitIntercept, [False, True])\\\n",
    "# .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "# .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=RegressionEvaluator(), numFolds=5)\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best model degree of polynomail = {}\".format(cvModel.bestModel.stages[1]._java_obj.getDegree()))\n",
    "print(\"Best model regParam value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getRegParam()))\n",
    "# print(\"Best model fitIntercept value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getFitIntercept()))\n",
    "# print(\"Best model elasticNetParam value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getElasticNetParam()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|load                |prediction         |\n",
      "+--------------------+-------------------+\n",
      "|78.0                |79.862267121874    |\n",
      "|25.55               |192.05373819449298 |\n",
      "|0.06666666666666667 |36.33467860900592  |\n",
      "|224.55              |179.4891507993166  |\n",
      "|390.18333333333334  |360.7349784057594  |\n",
      "|207.35              |120.52586536784167 |\n",
      "|410.7               |305.62444210653194 |\n",
      "|348.5833333333333   |326.5574258886327  |\n",
      "|192.83333333333334  |80.8198241981577   |\n",
      "|405.35              |208.47472550670767 |\n",
      "|381.4166666666667   |322.43669778166833 |\n",
      "|0.5                 |-19.935719146360526|\n",
      "|0.5166666666666667  |8.099124287187664  |\n",
      "|0.85                |70.7646618735991   |\n",
      "|0.03333333333333333 |68.31117260945405  |\n",
      "|350.8666666666667   |315.54429520967676 |\n",
      "|33.0                |330.0107539521547  |\n",
      "|0.016666666666666666|70.35487773400456  |\n",
      "|281.9               |336.5753369735944  |\n",
      "|0.03333333333333333 |267.7494050531194  |\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"load\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 99.107936\n",
      "r2: 0.582141\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = cvModel.bestModel.stages[2].summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-81e2c32824cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mcrossval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimatorParamMaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparamGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Run cross-validation, and choose the best set of parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Make predictions on test documents. cvModel uses the best model found (lrModel).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"hour\", \"minute\", \"prev_sent_bytes\", \"prev_received_bytes\", \n",
    "                                       \"prev_unique_request_count\", \"prev_unique_ip_count\"], outputCol=\"vectorized\")\n",
    "\n",
    "# df_t_4 = assembler.transform(df_t_3)\n",
    "polyExpansion = PolynomialExpansion(inputCol=\"vectorized\", outputCol=\"features\")\n",
    "lr = gbt = GBTRegressor(maxIter=100, seed=42, featuresCol=\"features\", labelCol=\"label\")\n",
    "pipeline = Pipeline(stages=[assembler, polyExpansion, lr])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(polyExpansion.degree, [1, 2, 3]).build()\n",
    "# .addGrid(lr.regParam, [0.1, 0.01, 0.001]).build()\n",
    "# .addGrid(lr.fitIntercept, [False, True])\\\n",
    "# .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "# .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=RegressionEvaluator(), numFolds=5)\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Predict the session length for a given IP\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.withColumn(\"client_ip\", F.split(F.col(\"client_port\"), ':')[0]).withColumn(\"timestamp\", F.col(\"timestamp\").substr(0,19).cast('timestamp'))\n",
    "df_2 = sessionize(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.groupby(\"client_ip\", \"session_id\").agg((F.unix_timestamp(F.max(\"timestamp\")) - F.unix_timestamp(F.min(\"timestamp\"))).alias(\"session_length\"), F.countDistinct(\"request\").alias(\"unique_url\"), F.avg(\"sent_bytes\").alias(\"sent_bytes\"), F.avg(\"received_bytes\").alias(\"received_bytes\"), F.avg(\"response_processing_time\").alias(\"response_processing_time\"))\n",
    "stats = df_3.agg(F.mean(\"sent_bytes\").alias(\"sent_bytes\"), F.mean(\"received_bytes\").alias(\"received_bytes\"), F.mean(\"response_processing_time\").alias(\"response_processing_time\")).collect()[0]\n",
    "avg_sent_bytes, avg_received_bytes, avg_response_processing_time = [stats[\"sent_bytes\"], stats[\"received_bytes\"], stats[\"response_processing_time\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"client_ip\").orderBy([\"session_id\"])\n",
    "df_4 = df_3.select(\"client_ip\", \"session_id\", \"session_length\", \"unique_url\", \\\n",
    "                   F.coalesce(F.lag(\"sent_bytes\").over(w), F.lit(avg_sent_bytes)).alias(\"prev_sent_bytes\"), \\\n",
    "                   F.coalesce(F.lag(\"received_bytes\").over(w), F.lit(avg_received_bytes)).alias(\"prev_received_bytes\"), \\\n",
    "                   F.coalesce(F.lag(\"response_processing_time\").over(w), F.lit(avg_response_processing_time)).alias(\"prev_response_processing_time\"))\n",
    "\n",
    "train, test = df_4.randomSplit([0.8, 0.2], seed=2019)\n",
    "training = train.withColumn(\"label\", F.col(\"session_length\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"prev_sent_bytes\", \"prev_received_bytes\", \n",
    "                                       \"prev_response_processing_time\"], outputCol=\"vectorized\")\n",
    "\n",
    "polyExpansion = PolynomialExpansion(inputCol=\"vectorized\", outputCol=\"features\")\n",
    "lr = LinearRegression(maxIter=100, featuresCol=\"features\", labelCol=\"label\")\n",
    "pipeline = Pipeline(stages=[assembler, polyExpansion, lr])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(polyExpansion.degree, [1, 2, 3])\\\n",
    ".addGrid(lr.regParam, [0.1, 0.01, 0.001]).build()\n",
    "# .addGrid(lr.fitIntercept, [False, True])\\\n",
    "# .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "# .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=RegressionEvaluator(), numFolds=5)\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model degree of polynomail = 1\n",
      "Best model regParam value = 0.1\n",
      "Best model fitIntercept value = True\n",
      "Best model elasticNetParam value = 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model degree of polynomail = {}\".format(cvModel.bestModel.stages[1]._java_obj.getDegree()))\n",
    "print(\"Best model regParam value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getRegParam()))\n",
    "# print(\"Best model fitIntercept value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getFitIntercept()))\n",
    "# print(\"Best model elasticNetParam value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getElasticNetParam()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+\n",
      "|session_length|prediction       |\n",
      "+--------------+-----------------+\n",
      "|13            |79.78774792224259|\n",
      "|0             |79.78774792224259|\n",
      "|41            |79.78774792224259|\n",
      "|2             |79.78774792224259|\n",
      "|17            |79.78774792224259|\n",
      "|625           |79.78774792224259|\n",
      "|0             |79.78774792224259|\n",
      "|4             |76.94537577309636|\n",
      "|0             |79.78774792224259|\n",
      "|47            |79.78774792224259|\n",
      "|109           |79.78774792224259|\n",
      "|600           |77.20623792486131|\n",
      "|55            |82.76495756548657|\n",
      "|75            |76.85845669144123|\n",
      "|238           |78.37433733301162|\n",
      "|28            |81.36845204146012|\n",
      "|298           |78.29581346710376|\n",
      "|3             |79.78774792224259|\n",
      "|0             |79.78774792224259|\n",
      "|80            |79.78774792224259|\n",
      "+--------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"session_length\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 148.044368\n",
      "r2: 0.000187\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = cvModel.bestModel.stages[2].summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Predict the number of unique URL visits by a given IP\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = train.withColumn(\"label\", F.col(\"unique_url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-17dea2470e02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcrossval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimatorParamMaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparamGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Run cross-validation, and choose the best set of parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Make predictions on test documents. cvModel uses the best model found (lrModel).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"prev_sent_bytes\", \"prev_received_bytes\", \n",
    "                                       \"prev_response_processing_time\"], outputCol=\"vectorized\")\n",
    "\n",
    "polyExpansion = PolynomialExpansion(inputCol=\"vectorized\", outputCol=\"features\")\n",
    "lr = LinearRegression(maxIter=100, featuresCol=\"features\", labelCol=\"label\")\n",
    "pipeline = Pipeline(stages=[assembler, polyExpansion, lr])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(polyExpansion.degree, [1, 2, 3])\\\n",
    ".addGrid(lr.regParam, [0.1, 0.01, 0.001]).build()\n",
    "# .addGrid(lr.fitIntercept, [False, True])\\\n",
    "# .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "# .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=RegressionEvaluator(), numFolds=5)\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best model degree of polynomail = {}\".format(cvModel.bestModel.stages[1]._java_obj.getDegree()))\n",
    "print(\"Best model regParam value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getRegParam()))\n",
    "# print(\"Best model fitIntercept value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getFitIntercept()))\n",
    "# print(\"Best model elasticNetParam value = {}\".format(cvModel.bestModel.stages[2]._java_obj.getElasticNetParam()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.select(\"unique_url\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = cvModel.bestModel.stages[2].summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "t = spark.createDataFrame([Row(date='2016-01-01', get_avg=5, get_first=1),\n",
    "                            Row(date='2016-01-01', get_avg=5, get_first=2),\n",
    "                            Row(date='2016-01-02', get_avg=10, get_first=3),\n",
    "                            Row(date='2016-01-02', get_avg=20, get_first=3),\n",
    "                            Row(date='2016-01-10', get_avg=30, get_first=3),\n",
    "                            Row(date='2016-01-10', get_avg=10, get_first=3),\n",
    "                            Row(date='2016-01-10', get_avg=20, get_first=3),\n",
    "                            Row(date='2016-01-12', get_avg=30, get_first=3),\n",
    "                            Row(date='2016-01-12', get_avg=8, get_first=4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+\n",
      "|(unix_timestamp(date, yyyy-MM-dd) - unix_timestamp(2016-01-01, yyyy-MM-dd))|\n",
      "+---------------------------------------------------------------------------+\n",
      "|                                                                          0|\n",
      "|                                                                          0|\n",
      "|                                                                      86400|\n",
      "|                                                                      86400|\n",
      "|                                                                     777600|\n",
      "|                                                                     777600|\n",
      "|                                                                     777600|\n",
      "|                                                                     950400|\n",
      "|                                                                     950400|\n",
      "+---------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.select(F.unix_timestamp(\"date\", 'yyyy-MM-dd')-F.unix_timestamp(F.lit(\"2016-01-01\"), 'yyyy-MM-dd')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "analyzedDataset": "2015_07_22_mktplace_shop_web_log_sample_sorted",
  "creator": "admin",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
